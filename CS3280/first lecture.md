# [1st Lecture](https://github.com/Hanif-K-Musaheb/Year-3-CS-UVM-Study-Abroad-/blob/main/CS3280/cs3280.md)
### PACT analysis
**P**eople conducting **A**ctivities in a **C**ontext using **T**echnology
# 1st chaptar
### Affordances
- is the relationship between properties of an object and the capabilities of an agent
- sometimes affordances are not visible
### Signifiers
- are indicators in teh physical social and digital world that can be interpretred meaningfully and communicate where actions should take place.
### Constraints
are things or ideas indicationg certain actions are not possible
### Mapping
- is when button/ways to perform an action are linked to said action
### Feedback
- is a reaction to response to a particular action
### Conceptual Models
are explantions of how something works
# 2nd chaptar
### The Gulfs of Execution and Evaluation ‚Äì
 - **The Gulf of Execution** is the gap between what a person wants to do and the actions available to achieve it.
 - **The Gulf of Evaluation** is the gap between what happened and whether the user can understand if it matches their goal. Designers must provide clear signifiers, feedback, and mappings to help users cross these gulfs.
## Seven Stages of Action
### Forming the Goal
 - You decide what you want to accomplish.
 - Example: ‚ÄúI want to print this document.‚Äù
 - Errors here ‚Üí Mistakes if the goal itself is wrong (e.g., thinking the wrong file needs to be printed).

# Lecture 18 sep
sample interview
### Forming the Intention
 - You decide what actions will achieve the goal.
 - Example: ‚ÄúI‚Äôll press the print button in Word.‚Äù
 - Errors here ‚Üí Rule-based mistakes (misapplying a rule, like thinking Ctrl+P always prints when the program doesn‚Äôt support it).
### Specifying the Action Sequence
 - You determine the exact steps needed.
 - Example: ‚ÄúClick File ‚Üí Print ‚Üí Select Printer.‚Äù
 - Errors here ‚Üí Knowledge-based mistakes (choosing wrong steps because of misunderstanding).
### Executing the Action
 - You physically carry out the steps.
 - Example: Clicking the print button.
 - Errors here ‚Üí Slips, such as clicking the wrong button or hitting the wrong keyboard shortcut.
### Perceiving the System State
 - You observe the system‚Äôs response.
 - Example: The printer icon appears or nothing seems to happen.
 - Errors here ‚Üí Slips or lapses if you fail to notice the feedback (e.g., missing a warning message).
### Interpreting the System State
 - You make sense of what happened.
 - Example: ‚ÄúThe printer is warming up‚Äù vs. ‚ÄúThe printer is broken.‚Äù
 - Errors here ‚Üí Mistakes if feedback is ambiguous or misleading (e.g., a vague ‚ÄúError 41‚Äù message).
### Evaluating the Outcome
 - You compare the result with your original goal.
 - Example: ‚ÄúDid the document actually print correctly?‚Äù
 - Errors here ‚Üí Mistakes if you misjudge success (e.g., assuming it printed when it didn‚Äôt).

# 3rd chaptar
### üß† Norman‚Äôs Two Types of Knowledge
#### Knowledge in the Head
 - Internalized knowledge people carry with them ‚Äî built from experience, culture, and learning.
 - **Examples**: how to ride a bike, remembering keyboard shortcuts, believing percentages always scale linearly.
#### knowledge in the World
 - Information provided by the environment, interface, or physical cues that guide behavior.
 - **Examples**: road signs, affordances of a door handle, a phone‚Äôs battery % display.
# 4th chaptar
## four types of constraints
 - Physical constraints ‚Üí the shape or size prevents incorrect use (e.g., a USB plug only fits one way).
 - Cultural constraints ‚Üí social conventions guide behavior (e.g., red means stop, green means go).
 - Semantic constraints ‚Üí meaning of the situation limits options (e.g., a rider sits facing forward on a bicycle).
 - Logical constraints ‚Üí process of elimination makes the correct choice obvious (e.g., puzzle pieces can only fit in one place).
   
## Discoverability
A design should make it obvious what can be done. This ties back to affordances and signifiers from earlier chapters. Users shouldn‚Äôt need a manual to figure out simple actions like turning on a faucet or pushing a door.


(complete another time)

 - logical grouping
 - location
 - saliency
 - simplicity
 - colors

# 5th chaptar - Human Error? No, Bad Design
### core idea
People often blame themselves for mistakes, but Norman argues that errors are usually the result of bad design, not human incompetence. Good design anticipates errors, prevents them when possible, and helps users recover gracefully.

### Why Errors Happen
 - Human limitations (memory lapses, distraction, stress).
 - Poor interfaces that confuse or mislead users.
 - Social and institutional pressures that force people into error-prone actions (e.g., rushing, multitasking).

### Two Types of Errors
 - **Slips** ‚Üí Right goal, wrong execution.
   - Examples: pressing the wrong button, typing a typo.
   - Two main categories: action-based slips (wrong physical action) and memory lapses (forgetting to act).
 - **Mistakes** ‚Üí Wrong goal or plan.
   - Examples: misunderstanding a medication label, misinterpreting a display.
   - Categories: **rule-based mistakes** (misapplying a rule), **knowledge-based mistakes** (lack of understanding), and **memory lapses**.

### Error Classification and the Seven Stages of Action
Norman maps slips and mistakes onto his seven-stage model (goal ‚Üí execution ‚Üí evaluation), showing how design flaws create opportunities for errors at different stages.

### Designing for Error
Don‚Äôt blame people ‚Üí design systems that anticipate human fallibility.

#### Strategies:
 - Constraints that prevent dangerous or impossible actions.
 - Forcing functions like ‚Äúlockouts‚Äù (car won‚Äôt start unless brake is pressed) or ‚Äúlock-ins‚Äù (confirm before deleting a file).
 - Clear feedback so users notice errors quickly.
 - Undo functions that allow recovery.
 - Resilience engineering: build systems that adapt and allow recovery rather than fail catastrophically.

### Automation Paradox
 - Automation can reduce some errors but introduce new ones.
 - Over-reliance on automation can make users complacent or unprepared when manual intervention is needed.

# 6th chapatar - Design Thinking
### Core Idea
This chapter explains how designers can systematically approach problem-solving, moving beyond intuition to structured processes. Norman emphasizes that successful design is not just about creativity but about finding the right problem to solve and iterating toward the best solution.
   
### Key Points
#### Solving the Correct Problem
 - Many design failures come from rushing to solve a problem before truly understanding it.
 - Good design starts with framing the problem properly through observation and research.
#### The Double-Diamond Model of Design
 - Developed by the British Design Council.
 - Two phases of divergence and convergence:
   - Diamond 1 ‚Üí Explore widely to understand the problem, then narrow down to define it.
   - Diamond 2 ‚Üí Explore many possible solutions, then narrow down to the best one.

#### The Human-Centered Design (HCD) Process
A cycle of:
 - **Observation** (watching real users in context).
 - **Ideation** (generating ideas).
 - **Prototyping** (building representations of solutions).
 - **Testing** (with real users).
 - **Iterative**: repeat and refine until solutions fit human needs.
 - **Reality Check**: It Doesn‚Äôt Really Work That Way
 - Norman notes that design in companies rarely follows neat processes.
   - Constraints like time, budgets, schedules, and organizational politics force compromises.
   - He humorously adds Norman‚Äôs Law: ‚ÄúThe day the product team is announced, it is behind schedule and over its budget.‚Äù

#### Complexity Is Good; Confusion Is Bad
 - Complexity in products is inevitable as needs grow
 - The real problem is poorly organized complexity, which causes confusion.
 - Good design makes complex systems understandable and manageable.

#### Standardization and Deliberate Difficulty
 - Standards (like QWERTY keyboards or traffic signs) make systems usable across contexts.
 - Sometimes things are deliberately made difficult for safety or control (e.g., childproof caps).

# 14 oct
## Ideation
### fidelity

# 16 oct
### human factors
focuses more on engineering
### sensors
